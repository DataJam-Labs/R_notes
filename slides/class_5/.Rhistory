# Repeat our function many times
nreps = 1000
mues_hat_bs1 <- replicate(nreps,bs_sample_mean(our_sample))
mues_hat_bs1 %>% as_tibble() %>% ggplot(aes(x=value)) + geom_density(size=0.5) + scale_color_ucscgb() +theme_bw()
---
title: "Simulation and resampling methods for inference and hypotheses testing "
institution: "University of Lucerne"
author: "Mauricio Bucca"
date: "11/7/2019"
output: html_document
---
```{r setup, include=FALSE, echo=TRUE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
```
## Classical approach to statistical inference
If $X$ is a random variable representing the outcome of a fair dice throw  ($X \in \{1,2,3,4,5,6\}$ where each value has a $\frac{1}{6}$ probability of occurence), then we know on theoretical basis (no need for data) that: $\mu_{X}=3.5$ and $\sigma_{X}=1.71$. Let's set this parameters.
```{r}
# Load packages
library("tidyverse")
library("rsample")
library("purrr")
library("ggsci")
set.seed(3234234)
# Teoretical parameters of a fair dice throw
mu = 3.5
sigma = (105/36)^(1/2)
n = 200
```
If we estimate $\mu_{X}=$ on a sample of size $n$ using the estimator $\bar{x}$ we can anticipate that: $E[\bar{x}]=\mu_{X}$ and $\sqrt{Var[\bar{x}]}= \frac{s}{\sqrt{n}}$.
```{r}
# A random sample of dice throws
our_sample <- sample(x = 1:6, size = n, replace = TRUE)
plot(table(our_sample), xlab = 'Values', ylab = 'Frequency', main = '500 Rolls of 1 Fair Dice')
mu_hat = mean(our_sample); mu_hat # Mean
sigma_hat = sd(our_sample); sigma_hat # Sd
# Using our theoretical knowledge of the sampling distribution we can anticipate that the sample mean follows normal distribution with the following parameters
mean_mu_hat <- mu_hat
sd_mu_hat   <- sigma_hat/(sqrt(n))
```
These results are obtained theoretically, analyzing the behavior of the estimator over infinite sample. Via simulation we can illustrate these properties:
```{r}
# Function tha draw random samples of size n (with replacement) frome set {1,2,3,4,5,6}
draw_sample <- function(nsize) {sample(x = 1:6, size = nsize, replace = TRUE)}
#example
draw_sample(10) %>% mean()
# Draw 1000 samples, compute the mean for each and store.
n_sim = 1000
mues_hat_sim <- replicate(n_sim, draw_sample(n) %>% mean())
mues_hat_sim %>% as_tibble() %>% print()
# Compute mean and sd of mu_hat
mean_mu_hat_sim <- mean(mues_hat_sim); mean_mu_hat_sim
sd_mu_hat_sim   <- sd(mues_hat_sim); sd_mu_hat_sim
```
We can compare the theoretically obtained parameters of the sampling distribution with those obtanained via simulation.
```{r}
# Mean of sampling distribution
mean_mu_hat; mean_mu_hat_sim
# Sd of sampling distribution
sd_mu_hat; sd_mu_hat_sim
```
The standarding version of the sampling distribution is independente of  can be compared to a standard-normal distribution.
```{r}
# create z-scores for distribution of sampling mean
mues_hat_z <- (mues_hat - mean(mues_hat))/sd(mues_hat)
# create a standard-normal
x <- seq(-4.5, 4.5, length=100)
hx <- dnorm(x)
# plot the two and compare
plot(x, hx, type="l", col="darkgreen" , xlab="x value",
ylab="Density", main="Comparison of t Distributions", lwd=2, ylim=c(0,0.45))
lines(density(mues_hat_z), col="blue", main="", lwd=2)
```
## The Boostrap
```{r}
# From theory we can anticipate properties of the sample mean:
mean_mu_hat
sd_mu_hat
mues_hat_theory <- rnorm(n_sim,mean_mu_hat,sd_mu_hat)
# Assume we don't the underlying distribution of the data or don't know these properties of our estimator. We can use the bootstrap
# to directly assess the empirical distribution of our estimate.
# We write a function that execute the bootstrap resampling
bs_sample_mean <- function(x) {
x_b <- sample(x,size=n,replace=TRUE)
return(mean(x_b))
}
# Repeat our function many times
nreps = 1000
mues_hat_bs1 <- replicate(nreps,bs_sample_mean(our_sample))
mues_hat_bs1 %>% as_tibble() %>% ggplot(aes(x=value)) + geom_density(size=0.5) + scale_color_ucscgb() +theme_bw()
mues_hat_bs1 %>% as_tibble() %>% ggplot(aes(x=value)) + geom_density(size=0.5) +
scale_color_ucscgb() + theme_bw() +
labs(main="Empirical distribution function")
mues_hat_bs1 %>% as_tibble() %>% ggplot(aes(x=value)) + geom_density(size=0.5) +
scale_color_ucscgb() + theme_bw() +
labs(title="Empirical distribution function")
mues_hat_bs1 %>% as_tibble() %>% ggplot(aes(x=value, color="cyan")) + geom_density(size=0.5) +
scale_color_ucscgb() + theme_bw() +
labs(title="Empirical distribution function")
mues_hat_bs1 %>% as_tibble() %>% ggplot(aes(x=value, color="blue")) + geom_density(size=0.5) +
scale_color_ucscgb() + theme_bw() +
labs(title="Empirical distribution function")
mues_hat_bs1 %>% as_tibble() %>% ggplot(aes(x=value, colour="blue")) + geom_density(size=0.5) +
scale_color_ucscgb() + theme_bw() +
labs(title="Empirical distribution function")
(3.472+3.440)/2
2.75 - 4
?t.test
########################### Load data ###########################
library(rsample)
library(carData)
data(SLID)
ourdata <- SLID
# remove NAs
ourdata <- ourdata %>% na.omit()
# Look at data
ourdata %>% as_tibble()
# A regression model
our_model <- lm(log(wages) ~ sex + education + language, data=ourdata)
summary_our_model <- summary(our_model); summary_our_model
######################## Inference via MC ########################
n =  length(our_model$fitted.values)
wage_hat = our_model$fitted.values
sigma = summary_our_model$sigma
nreps = 1000
our_mc <- function() {
logwage_m <- rnorm(n,mean=wage_hat,sd=sigma)
ourdata_m <- cbind(ourdata,logwage_m)
model_m   <- lm(logwage_m ~ sex + education + language, data=ourdata_m)
coefs_m   <- model_m$coefficients
return(coefs_m)
}
coefs_mc_dist <- replicate(nreps,our_mc())
coefs_mc_dist <- coefs_mc_dist %>% t() %>% as_tibble()
# Montecarlo distribution of coeffs.
coefs_mc_dist %>% ggplot(aes(x=sexMale)) + geom_density()
# Parameters of montecarlo distribution of coeffs.
beta_sexMale_mc <- mean(coefs_mc_dist$sexMale); beta_sexMale_mc
se_sexMale_mc   <- sd(coefs_mc_dist$sexMale); se_sexMale_mc
ci_sexMale_q_mc <- quantile(coefs_mc_dist$sexMale,p=c(0.025,0.975)); ci_sexMale_q_mc
ci_sexMale_normap_mc <- c(beta_sexMale_mc-2*se_sexMale_mc,beta_sexMale_mc+2*se_sexMale_mc); ci_sexMale_normap_mc
# Montecarlo distribution of linear or non linear combinarion of parameters.
coefs_mc_dist %>%
ggplot(aes(x=languageOther - languageFrench)) + geom_density()
# estimates with Ci of linear or non linear combinarion of parameters.
coefs_mc_dist %>%
dplyr::summarise(ratio=mean(languageOther - languageFrench),
ll=quantile(languageOther - languageFrench,p=0.025),
ul=quantile(languageOther - languageFrench,p=0.975))
coefs_mc_dist %>% ggplot(aes(x=sexMale)) + geom_density()
# direct computations of quantities of interest
sum(coefs_mc_dist$languageOther > coefs_mc_dist$languageFrench)/length(coefs_mc_dist$languageOther)
ourdata %>% as_tibble()
boots <- bootstraps(ourdata, times = nreps)
boots
boots$splits[[1]] %>% analysis() %>% as_tibble()
ourdata
boots <- bootstraps(ourdata, times = nreps)
library(tidyverse)
library(rsample)
install.packages("rsample", lib="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
install.packages("rsample", lib="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
library(rsample)
boots <- bootstraps(ourdata, times = nreps)
boots
boots$splits[[1]] %>% analysis() %>% as_tibble()
lowess_fit <- function(split){
lowess(analysis(split)$wages, analysis(split)$education)
}
boots %>%
mutate(lowess_points = map(splits, lowess_fit))
boots <- bootstraps(ourdata, times = 20)
boots
boots$splits[[1]] %>% analysis() %>% as_tibble()
lowess_fit <- function(split){
lowess(analysis(split)$wages, analysis(split)$education)
}
boots %>%
mutate(lowess_points = map(splits, lowess_fit))
boots %>%
mutate(lowess_points = map(splits, lowess_fit)) %>%
select(id, lowess_points)
boots %>%
mutate(lowess_points = map(splits, lowess_fit)) %>%
select(id, lowess_points) %>%  unnest()
boots %>%
mutate(lowess_points = map(splits, lowess_fit)) %>%
select(id, lowess_points) %>%  unnest( lowess_points)
boots %>%
mutate(lowess_points = map(splits, lowess_fit)) %>%
select(id, lowess_points) %>%
mutate_if(is.list, map, as_data_frame) %>%
unnest()
boots %>%
mutate(lowess_points = map(splits, lowess_fit)) %>%
select(id, lowess_points) %>%
mutate_if(is.list, map, as_data_frame) %>%
unnest() %>%
distinct()
boots %>%
mutate(lowess_points = map(splits, lowess_fit)) %>%
select(id, lowess_points) %>%
mutate_if(is.list, map, as_data_frame) %>%
unnest() %>%
distinct()  %>%
geom_line(aes(x = x, y = y, color = id),
alpha = 0.5) +
theme(legend.position = 'none')
boots %>%
mutate(lowess_points = map(splits, lowess_fit)) %>%
select(id, lowess_points) %>%
mutate_if(is.list, map, as_data_frame) %>%
unnest() %>%
distinct()  %>% ggplot(aes(x = x, y = y, color = id) %>%
geom_line(),
alpha = 0.5) +
theme(legend.position = 'none')
boots %>%
mutate(lowess_points = map(splits, lowess_fit)) %>%
select(id, lowess_points) %>%
mutate_if(is.list, map, as_data_frame) %>%
unnest() %>%
distinct()  %>%
ggplot(aes(x = x, y = y, color = id)) +
geom_line(alpha = 0.5) +
theme(legend.position = 'none')
boots %>%
mutate(lowess_points = map(splits, lowess_fit)) %>%
select(id, lowess_points) %>%
mutate_if(is.list, map, as_data_frame) %>%
unnest() %>%
#distinct()  %>%
ggplot(aes(x = x, y = y, color = id)) +
geom_line(alpha = 0.5) +
theme(legend.position = 'none')
boots %>%
mutate(lowess_points = map(splits, lowess_fit)) %>%
select(id, lowess_points) %>%
#mutate_if(is.list, map, as_data_frame) %>%
unnest() %>%
ggplot(aes(x = x, y = y, color = id)) +
geom_line(alpha = 0.5) +
theme(legend.position = 'none')
boots %>%
mutate(lowess_points = map(splits, lowess_fit)) %>%
select(id, lowess_points) %>%
mutate_if(is.list, map, as_data_frame)
boots %>%
mutate(lowess_points = map(splits, lowess_fit)) %>%
select(id, lowess_points) %>%
mutate(as_data_frame lowess_points())
boots %>%
mutate(lowess_points = map(splits, lowess_fit)) %>%
select(id, lowess_points) %>%
mutate(as_data_frame(lowess_points))
boots %>%
mutate(lowess_points = map(splits, lowess_fit)) %>%
select(id, lowess_points) %>%
mutate(data.frame(lowess_points))
boots %>%
mutate(lowess_points = map(splits, lowess_fit)) %>%
select(id, lowess_points) %>%
mutate_if(is.list, map, as_data_frame) %>%
unnest()
lowess_fit <- function(split){
lowess(analysis(split)$wages, analysis(split)$education)
}
############ Lowess via bootstrap ############
# creates boostrap samples
boots <- bootstraps(ourdata, times = 100)
boots
boots$splits[[1]] %>% analysis() %>% as_tibble()
# function to implement within each sample
lowess_fit <- function(split){
lowess(analysis(split)$wages, analysis(split)$education)
}
# look at and plot results within each sample
boots %>%
mutate(lowess_points = map(splits, lowess_fit)) %>%
select(id, lowess_points) %>%
mutate_if(is.list, map, as_data_frame) %>%
unnest() %>%
ggplot(aes(x = x, y = y, color = id)) +
geom_line(alpha = 0.5) +
theme(legend.position = 'none')
boots %>%
mutate(lowess_points = map(splits, lowess_fit)) %>%
select(id, lowess_points) %>%
mutate_if(is.list, map, as_data_frame) %>%
unnest() %>%
ggplot(aes(x = x, y = y, color = id)) +
geom_line(alpha = 0.1) +
theme(legend.position = 'none') +
labs(x="education",y="wages")
boots %>%
mutate(lowess_points = map(splits, lowess_fit)) %>%
select(id, lowess_points) %>%
mutate_if(is.list, map, as_data_frame) %>%
unnest() %>%
ggplot(aes(x = x, y = y, color = id)) +
geom_line(alpha = 0.2) +
theme(legend.position = 'none') +
labs(x="education",y="wages")
# creates boostrap samples
boots <- bootstraps(ourdata, times = nreps)
boots
boots$splits[[1]] %>% analysis() %>% as_tibble()
# creates boostrap samples
boots <- bootstraps(ourdata, times = nreps)
boots
boots$splits[[1]] %>% analysis() %>% as_tibble()
# function to implement within each sample (regression model)
lm_fit <- function(split){
model_bs = lm(logwage_m ~ sex + education + language, data=analysis(split))
}
boots %>%
mutate(lowess_points = map(splits, lm_fit))
# creates boostrap samples
boots <- bootstraps(ourdata, times = nreps)
boots
boots$splits[[1]] %>% analysis() %>% as_tibble()
# function to implement within each sample (regression model)
lm_fit <- function(split){
model_bs = lm(log(wages) ~ sex + education + language, data=analysis(split))
}
# look at and plot results within each sample
boots %>%
mutate(fit = map(splits, lm_fit))
boots %>%
mutate(fit = map(splits, lm_fit), estimates=map(fit,tidy))
boots %>%
mutate(fit = map(splits, lm_fit), estimates=map(fit,tidy)) %>%
unnest()
boots %>%
mutate(fit = map(splits, lm_fit), estimates=map(fit,tidy)) %>%
select(id,estimates) %>%
unnest()
coefs_bs_dist <- boots %>%
mutate(fit = map(splits, lm_fit), estimates=map(fit,tidy)) %>%
select(id,estimates) %>%
unnest()
coefs_bs_dist
coefs_bs_dist %>%
select(sexMale) %>%
ggplot(aes(x=estimate)) + geom_density()
coefs_bs_dist %>%
filter(estimate=="sexMale")
coefs_bs_dist %>%
filter(term=="sexMale")
coefs_bs_dist %>%
filter(term=="sexMale") %>%
ggplot(aes(x=estimate)) + geom_density()
coefs_bs_dist %>%
filter(term=="sexMale") %>%
ggplot(aes(x=estimate)) + geom_density()
coefs_bs_dist %>% filter(term=="sexMale")
coefs_bs_dist %>% filter(term=="sexMale") %>% with(mean(estime))
coefs_bs_dist %>% filter(term=="sexMale") %>% with(mean(estimate))
beta_sexMale_bs <- coefs_bs_dist %>% filter(term=="sexMale") %>% with(mean(estimate)); beta_sexMale_bs
se_sexMale_bs   <- coefs_bs_dist %>% filter(term=="sexMale") %>% with(sd(estimate)); se_sexMale_bs
se_sexMale_bs
se_sexMale_mc
coefs_bs_dist %>% filter(term=="sexMale") %>% with(quantile(estimate,p=c(0.025,0.975)))
c(beta_sexMale_bs-2*se_sexMale_bs,beta_sexMale_bs+2*se_sexMale_bs)
beta_sexMale_bs <- coefs_bs_dist %>% filter(term=="sexMale") %>% with(mean(estimate)); beta_sexMale_bs
se_sexMale_bs   <- coefs_bs_dist %>% filter(term=="sexMale") %>% with(sd(estimate)); se_sexMale_bs
ci_sexMale_q_bs <- coefs_bs_dist %>% filter(term=="sexMale") %>%
with(quantile(estimate,p=c(0.025,0.975))); ci_sexMale_q_bs
ci_sexMale_normap_bs <- c(beta_sexMale_bs-2*se_sexMale_bs,beta_sexMale_bs+2*se_sexMale_bs); ci_sexMale_normap_bs
coefs_bs_dist
coefs_bs_dist %>% select(id,term,estimate)
coefs_bs_dist %>% select(id,term,estimate) %>%
spread(term,estimate)
coefs_bs_dist %>% select(id,term,estimate) %>%
spread(term,estimate) %>%
mutate(wage_male =   exp(`(Intercept)` + education*mean(ourdata$education) + sexMale)) %>%
mutate(wage_female = exp(`(Intercept)` + education*mean(ourdata$education)))
coefs_bs_dist %>% select(id,term,estimate) %>%
spread(term,estimate) %>%
mutate(wage_male =   exp(`(Intercept)` + education*mean(ourdata$education) + sexMale)) %>%
mutate(wage_female = exp(`(Intercept)` + education*mean(ourdata$education))) %>%
mutate(gender_gap = wage_male - wage_female)
coefs_bs_dist %>% select(id,term,estimate) %>%
spread(term,estimate) %>%
mutate(wage_male =   exp(`(Intercept)` + education*mean(ourdata$education) + sexMale)) %>%
mutate(wage_female = exp(`(Intercept)` + education*mean(ourdata$education))) %>%
mutate(gender_gap = wage_male - wage_female) %>%
ggplot(aes(x=gender_gap)) + geom_density()
our_sample
ourdata
ourdata$wages %>% with(mean())
ourdata$wages %>% mean()
coefs_bs_dist %>% select(id,term,estimate) %>%
spread(term,estimate) %>%
mutate(wage_male =   exp(`(Intercept)` + education*mean(ourdata$education) + sexMale)) %>%
mutate(wage_female = exp(`(Intercept)` + education*mean(ourdata$education))) %>%
mutate(gender_gap_perc = (wage_male - wage_female)/wage_male) %>%
ggplot(aes(x=gender_gap_perc)) + geom_density()
summary_our_model
coefs_bs_dist %>% select(id,term,estimate) %>%
spread(term,estimate) %>%
mutate(wage_male =   exp(`(Intercept)` + education*mean(ourdata$education) + sexMale)) %>%
mutate(wage_female = exp(`(Intercept)` + education*mean(ourdata$education))) %>%
mutate(gender_gap = wage_male - wage_female) %>%
ggplot(aes(x=gender_gap)) + geom_density()
source("10_mlogit.R")
source("11_plothypotheses.R")
install.packages(c("deldir", "effects", "spatstat", "spatstat.data", "spatstat.utils"))
2+2
install_github('andreacirilloac/updateR')
install.packages("devtools")
library(devtools)
install_github('andreacirilloac/updateR')
library(updateR)
install_github('andreacirilloac/updateR')
install.packages(c("bookdown", "bookdownplus"))
sqrt(exp(-3))
log(1/(0.2231302*0.2231302))
xaringan:::inf_mr()
bookdown:::serve_book()
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
install.packages("tidyverse")
xaringan:::inf_mr()
$$g(x) \approx g(\mu) + g^{'}(\mu)( x - \mu)$$
$$g(x) \approx g(\mu) + g^{'}(\mu)( x - \mu)$$
Por series de Taylor:
$$g(X) \approx g(\theta) + g^{'}(\theta)(X - \theta) $$
<br>
install.packages("msm", lib="/Library/Frameworks/R.framework/Versions/4.0/Resources/library")
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
sample(affairsdata,size=nrows(affairsdata),replace=TRUE)
nrows(affairsdata)
nrow(affairsdata)
x_b <- sample(affairsdata,size=nrow(affairsdata),replace=TRUE)
xb
sample(affairsdata,size=nrow(affairsdata),replace=TRUE)
sample(affairsdata,size=nrow(affairsdata),replace=TRUE)
sample(affairsdata,size=nrow(affairsdata),replace=TRUE)
sample(affairsdata,size=nrow(affairsdata),replace=TRUE)
?sample
?n_sample
?sample_n
sample_n(affairsdata,size=nrow(affairsdata),replace=TRUE)
sample_n(affairsdata,size=nrow(affairsdata),replace=TRUE)
sample_n(affairsdata,size=nrow(affairsdata),replace=TRUE)
sample_n(affairsdata,size=nrow(affairsdata),replace=TRUE)
sample_n(affairsdata,size=nrow(affairsdata),replace=TRUE)
sample_n(affairsdata,size=nrow(affairsdata),replace=TRUE)
sample_n(affairsdata,size=nrow(affairsdata),replace=TRUE)
sample_n(affairsdata,size=nrow(affairsdata),replace=TRUE)
sample_n(affairsdata,size=nrow(affairsdata),replace=TRUE)
bs_beta2  <- function(x) {
data_b  <- sample_n(affairsdata,size=nrow(affairsdata),replace=TRUE)
logit_b <- glm(everaffair_d ~ factor(sex) + ym, family=binomial(link="logit"), data=data_b)
beta2_b <- logit_b$coefficients[3]
return(beta2_b)
}
bs_beta2()
bs_beta2()
bs_beta2()
bs_beta2()
bs_beta2()
nreps = 1000
betas2_bs <- replicate(nreps,bs_beta2)
head(betas2_bs)
nreps = 1000
betas2_bs <- replicate(nreps,bs_beta2)
head(betas2_bs)
nreps = 1000
betas2_bs <- replicate(nreps,bs_beta2() )
head(betas2_bs)
xaringan:::inf_mr()
library("readr")
setwd(
"~/Library/Mobile Documents/com~apple~CloudDocs/Teaching/ISUC/2020_2_data_analysis_r/repo/slides/class_5/")
# leer archivo csv
data_casen_csv <- read_csv("sample_casen2017.csv")
data_casen_csv
library("carData")
data("Chile")
data("Chile")
datos_chile <- Chile
rm(Chile) # remueve "flotante"
Chile %>% glimpse()
table(Chile$population)
datos_chile <- datos_chile <%>% mutate(year = 1988)
datos_chile <- datos_chile %>% mutate(year = 1988)
Chile %>% glimpse()
datos_chile %>% glimpse()
data_chile <- data_chile %>% mutate(birthyear = year - age)
datos_chile <- datos_chile %>% mutate(birthyear = year - age)
datos_chile %>% glimpse()
summary(datos_chile$birthyear)
1973 - 18
1973 - 15
datos_chile <-  datos_chile %>% mutate(cohort73 = case_when(birthyear <= (1973 - 15) ~ 1,
birthyear > (1973 - 15) ~ 0)
)
datos_chile %>% glimpse()
datos_chile <-  datos_chile %>% group_by(region,educaction) %>%
mutate(income_region_educ = mean(income, na.rm = T))
datos_chile <-  datos_chile %>% group_by(region,education) %>%
mutate(income_region_educ = mean(income, na.rm = T))
datos_chile %>% glimpse()
install.packages("carData", lib="/Library/Frameworks/R.framework/Versions/4.0/Resources/library")
install.packages("carData", lib="/Library/Frameworks/R.framework/Versions/4.0/Resources/library")
library("carData")
